{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!pip install ultralytics tqdm torch torchvision"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import random\n",
    "from deep_sort.tracker import Tracker\n",
    "from deep_sort.deep.extractor import Extractor\n",
    "from deep_sort.deep.configuration import ResNetConfiguration\n",
    "from deep_sort.deep.weights import RESNET18_WEIGHTS\n",
    "\n",
    "\n",
    "resnet = ResNetConfiguration(\n",
    "    base=\"resnet18\", \n",
    "    weights_path=RESNET18_WEIGHTS, \n",
    "    use_cuda=True\n",
    ")\n",
    "extractor = Extractor(model=resnet, batch_size=1)\n",
    "\n",
    "tracker = Tracker(\n",
    "    feature_extractor=extractor\n",
    ")\n",
    "\n",
    "colors = [(\n",
    "    random.randint(0, 255), \n",
    "    random.randint(0, 255), \n",
    "    random.randint(0, 255)) for j in range(10)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T23:51:35.459597Z",
     "start_time": "2024-04-01T23:51:34.734599Z"
    }
   },
   "id": "8e6a4d02d5ac2d64",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8x.pt to 'yolov8x.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131M/131M [02:02<00:00, 1.12MB/s] \n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8x.pt\")\n",
    "detection_threshold = 0.5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T23:53:42.242819Z",
     "start_time": "2024-04-01T23:51:37.639822Z"
    }
   },
   "id": "8de15e9f708678ee",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 100/100 [03:02<00:00,  1.83s/frame]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "\n",
    "video_path = \"data/running.mp4\"\n",
    "video_out_path = \"out_running.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "ret, frame = cap.read()\n",
    "\n",
    "cap_out = cv2.VideoWriter(\n",
    "    video_out_path,\n",
    "    cv2.VideoWriter_fourcc(*\"MP4V\"),\n",
    "    cap.get(cv2.CAP_PROP_FPS),\n",
    "    (frame.shape[1], frame.shape[0])\n",
    ")\n",
    "\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frame_count = 100\n",
    "\n",
    "progress_bar = tqdm(total=frame_count, desc=\"Processing frames\", unit=\"frame\")\n",
    "\n",
    "while ret:\n",
    "    if frame is None:\n",
    "        break\n",
    "        \n",
    "    if cap.get(cv2.CAP_PROP_POS_FRAMES) > frame_count:\n",
    "        break\n",
    "    \n",
    "    results = model.predict(\n",
    "        frame, \n",
    "        verbose=False, \n",
    "        conf=detection_threshold\n",
    "    )\n",
    "    result = results[0]\n",
    "    \n",
    "    detections = []\n",
    "    for r in result.boxes.data.tolist():\n",
    "        x1, y1, x2, y2, score, class_id = r\n",
    "        x1 = int(x1)\n",
    "        x2 = int(x2)\n",
    "        y1 = int(y1)\n",
    "        y2 = int(y2)\n",
    "        class_id = int(class_id)\n",
    "\n",
    "        if score > detection_threshold:\n",
    "            detections.append([x1, y1, x2, y2, score, class_id])\n",
    "\n",
    "    tracker.update(frame, detections)\n",
    "\n",
    "    for track in tracker.tracks:\n",
    "        x1, y1, x2, y2 = track.to_tlbr()\n",
    "        track_id = track.track_id\n",
    "        class_id = track.class_id\n",
    "\n",
    "        color = colors[track_id % len(colors)]\n",
    "\n",
    "        cv2.rectangle(\n",
    "            frame,\n",
    "            (int(x1), int(y1)),\n",
    "            (int(x2), int(y2)),\n",
    "            color,\n",
    "            3\n",
    "        )\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            f\"ID: {track_id} | Class: {model.names[class_id]}\",\n",
    "            (int(x1), int(y1) - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            colors[track_id % len(colors)],\n",
    "            2\n",
    "        )\n",
    "        \n",
    "    cap_out.write(frame)\n",
    "        \n",
    "    progress_bar.update(1)\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "cap.release()\n",
    "cap_out.release()\n",
    "progress_bar.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T23:56:45.177946Z",
     "start_time": "2024-04-01T23:53:42.244817Z"
    }
   },
   "id": "79c6d7377ce2691f",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fa1832fe4f7a1534",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
