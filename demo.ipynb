{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install ultralytics tqdm torch torchvision"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import random\n",
    "from deep_sort.tracker import Tracker\n",
    "from deep_sort.deep.extractor import Extractor\n",
    "from deep_sort.deep.configuration import ResNetConfiguration\n",
    "from deep_sort.deep.weights import RESNET18_WEIGHTS\n",
    "\n",
    "\n",
    "resnet = ResNetConfiguration(\n",
    "    base=\"resnet18\", \n",
    "    weights_path=RESNET18_WEIGHTS, \n",
    "    use_cuda=True\n",
    ")\n",
    "extractor = Extractor(model=resnet, batch_size=1)\n",
    "\n",
    "tracker = Tracker(\n",
    "    feature_extractor=extractor\n",
    ")\n",
    "\n",
    "colors = [(\n",
    "    random.randint(0, 255), \n",
    "    random.randint(0, 255), \n",
    "    random.randint(0, 255)) for j in range(10)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T17:09:10.856019Z",
     "start_time": "2024-04-02T17:09:01.605867Z"
    }
   },
   "id": "8e6a4d02d5ac2d64",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8x.pt\")\n",
    "detection_threshold = 0.5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T17:09:18.613942Z",
     "start_time": "2024-04-02T17:09:13.254483Z"
    }
   },
   "id": "8de15e9f708678ee",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "\n",
    "video_path = \"data/running.mp4\"\n",
    "video_out_path = \"out_running.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "ret, frame = cap.read()\n",
    "\n",
    "cap_out = cv2.VideoWriter(\n",
    "    video_out_path,\n",
    "    cv2.VideoWriter_fourcc(*\"MP4V\"),\n",
    "    cap.get(cv2.CAP_PROP_FPS),\n",
    "    (frame.shape[1], frame.shape[0])\n",
    ")\n",
    "\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frame_count = 100\n",
    "\n",
    "progress_bar = tqdm(total=frame_count, desc=\"Processing frames\", unit=\"frame\")\n",
    "\n",
    "while ret:\n",
    "    if frame is None:\n",
    "        break\n",
    "        \n",
    "    if cap.get(cv2.CAP_PROP_POS_FRAMES) > frame_count:\n",
    "        break\n",
    "    \n",
    "    results = model.predict(\n",
    "        frame, \n",
    "        verbose=False, \n",
    "        conf=detection_threshold\n",
    "    )\n",
    "    result = results[0]\n",
    "    \n",
    "    detections = []\n",
    "    for r in result.boxes.data.tolist():\n",
    "        x1, y1, x2, y2, score, class_id = r\n",
    "        x1 = int(x1)\n",
    "        x2 = int(x2)\n",
    "        y1 = int(y1)\n",
    "        y2 = int(y2)\n",
    "        class_id = int(class_id)\n",
    "\n",
    "        if score > detection_threshold:\n",
    "            detections.append([x1, y1, x2, y2, score, class_id])\n",
    "\n",
    "    tracker.update(frame, detections)\n",
    "\n",
    "    for track in tracker.tracks:\n",
    "        x1, y1, x2, y2 = track.to_tlbr()\n",
    "        track_id = track.track_id\n",
    "        class_id = track.class_id\n",
    "\n",
    "        color = colors[track_id % len(colors)]\n",
    "\n",
    "        cv2.rectangle(\n",
    "            frame,\n",
    "            (int(x1), int(y1)),\n",
    "            (int(x2), int(y2)),\n",
    "            color,\n",
    "            3\n",
    "        )\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            f\"ID: {track_id} | Class: {model.names[class_id]}\",\n",
    "            (int(x1), int(y1) - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            colors[track_id % len(colors)],\n",
    "            2\n",
    "        )\n",
    "        \n",
    "    cap_out.write(frame)\n",
    "        \n",
    "    progress_bar.update(1)\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "cap.release()\n",
    "cap_out.release()\n",
    "progress_bar.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T17:12:41.276807Z",
     "start_time": "2024-04-02T17:09:20.867585Z"
    }
   },
   "id": "79c6d7377ce2691f",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fa1832fe4f7a1534",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
